{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08deeb5-3d7f-4838-8a87-cb98b557074d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入城市名（默认值：徐州）： xuzhou\n",
      "请输入保存文件名（包括文件后缀，如PM25_data_xuzhou.xlsx，默认值：PM25_data_xuzhou.xlsx）： PM25_data_xuzhou.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "城市名： xuzhou\n",
      "200 请求成功\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202412.html\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202411.html\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202410.html\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202409.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202408.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202407.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202406.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202405.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202404.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202403.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202402.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202401.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202312.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202311.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202310.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202309.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202308.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202307.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202306.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202305.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202304.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202303.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202302.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202301.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202212.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202211.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202210.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202209.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202208.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202207.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202206.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202205.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202204.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202203.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202202.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202201.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202112.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202111.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202110.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202109.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202108.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202107.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202106.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202105.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202104.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202103.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202102.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202101.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202012.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202011.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202010.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202009.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202008.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202007.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202006.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202005.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202004.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202003.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202002.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-202001.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201912.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201911.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201910.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201909.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201908.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201907.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201906.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201905.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201904.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201903.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201902.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201901.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201812.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201811.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201810.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201809.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201808.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201807.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201806.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201805.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201804.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201803.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201802.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201801.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201712.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201711.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201710.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201709.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201708.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201707.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201706.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201705.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201704.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201703.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201702.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201701.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201612.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201611.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201610.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201609.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201608.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201607.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201606.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201605.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201604.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201603.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201602.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201601.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201512.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201511.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201510.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201509.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201508.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201507.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201506.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201505.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201504.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201503.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201502.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201501.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201412.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201411.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201410.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201409.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201408.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201407.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201406.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201405.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201404.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201403.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201402.html\n",
      "数据爬取成功！\n",
      "爬取子url： http://www.tianqihoubao.com/aqi/xuzhou-201401.html\n",
      "数据爬取成功！\n",
      "数据爬取成功！\n",
      "数据爬取成功！\n",
      "数据爬取成功！\n",
      "写入成功\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pypinyin\n",
    "import threading\n",
    "import pandas as pd\n",
    "from queue import Queue\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class PM_DATA:\n",
    "    '''\n",
    "    获取天气后报网站城市天气PM数据，多线程版本,存入excel\n",
    "    '''\n",
    "    def __init__(self, name, save_filename):\n",
    "\n",
    "        # 数据存入EXCEL的字典格式\n",
    "        self.index_list = ['日期', '质量等级', 'AQI指数', '当天AQI排名', 'PM2.5', 'PM10', 'So2', 'No2', 'Co', 'O3']\n",
    "        self.total_list = {}\n",
    "        self.total_list['日期'] = []\n",
    "        self.total_list['质量等级'] = []\n",
    "        self.total_list['AQI指数'] = []\n",
    "        self.total_list['当天AQI排名'] = []\n",
    "        self.total_list['PM2.5'] = []\n",
    "        self.total_list['PM10'] = []\n",
    "        self.total_list['So2'] = []\n",
    "        self.total_list['No2'] = []\n",
    "        self.total_list['Co'] = []\n",
    "        self.total_list['O3'] = []\n",
    "\n",
    "        self.name = change_c(name)\n",
    "        self.main_url = 'http://www.tianqihoubao.com/aqi/'\n",
    "        self.headers = {\n",
    "            # TODO 改为自己电脑的User-Agent\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.100 Safari/537.36',\n",
    "            'Host': 'www.tianqihoubao.com',\n",
    "            'Referer': 'http://www.tianqihoubao.com/aqi/'\n",
    "        }\n",
    "\n",
    "        self.save_filename = save_filename\n",
    "\n",
    "    def index_request(self):\n",
    "        '''\n",
    "        某城市页请求\n",
    "        :return: HTML数据\n",
    "        '''\n",
    "        r = requests.get(self.main_url + self.name + '.html', headers=self.headers)\n",
    "        # 判断请求是否成功\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(r.status_code, '请求成功')\n",
    "            return r.text\n",
    "        else:\n",
    "            print(r.status_code, '请求失败')\n",
    "            return None\n",
    "\n",
    "    def parse_index_html(self, queue):\n",
    "        '''\n",
    "        解析该城市提供的所有PM日期URL链接\n",
    "        :return: 日期列表\n",
    "        '''\n",
    "        index_html = self.index_request()\n",
    "        if index_html is None:\n",
    "            return False\n",
    "        soup = BeautifulSoup(index_html, 'html.parser')  # 格式化HTML\n",
    "        try:\n",
    "            # 根据HTML结构，解析HTML  ---> 观察下网页的HTML的结构就了解了\n",
    "            content = soup.select_one('div.box.p').find_all_next('ul')[0]\n",
    "            son_url = content.find_all('a')\n",
    "            for attr in son_url:\n",
    "                # 从HTML的href属性中解析出URL，并对日期进行过滤\n",
    "                href_str = attr['href']\n",
    "                fir_date = href_str.split('-')\n",
    "                fin_date = fir_date[1].split('.')[0]\n",
    "                if fin_date <= '202412' and fin_date >= '201401':\n",
    "                    url = self.main_url + self.name + '-' + fin_date + '.html'\n",
    "                    queue.put(url)  # 将子url放入队列\n",
    "        except:\n",
    "            print('主HTML解析失败（可能页面被更新过）')\n",
    "\n",
    "    def son_request(self, detail_url_list):\n",
    "        '''\n",
    "        某城市月份PM数据请求\n",
    "        :return: 获取的总数据 ---> 字典\n",
    "        '''\n",
    "        while True:\n",
    "            url = detail_url_list.get()  # Queue队列的get方法用于从队列中提取元素\n",
    "            print('爬取子url：', url)\n",
    "            r = requests.get(url, headers=self.headers)\n",
    "            self.parse_son_html(r.text)\n",
    "            # 队列为空时退出循环\n",
    "            if detail_url_list.qsize() == 0:\n",
    "                break\n",
    "\n",
    "    def parse_son_html(self, son_html):\n",
    "        '''\n",
    "        解析子页面,获取PM数据\n",
    "        :param son_html: 子页面HTML数据\n",
    "        :param date_num: 月份\n",
    "        :return: 月级PM数据 ---> 字典\n",
    "        '''\n",
    "        soup = BeautifulSoup(son_html, 'html.parser')\n",
    "        try:\n",
    "            # 解析HTML中的table\n",
    "            content = soup.table.find_all('tr')\n",
    "            for index, value in enumerate(content):\n",
    "                if index == 0:   # 过滤table中的索引名字\n",
    "                    pass\n",
    "                else:\n",
    "                    for i, j in enumerate(value.find_all('td')):\n",
    "                        # 清除字符串包含的特殊字符\n",
    "                        a = re.compile(r'\\n|&nbsp|\\xa0|\\\\xa0|\\u3000|\\\\u3000|\\\\u0020|\\u0020|\\t|\\r')\n",
    "                        clean_str = a.sub('', j.string)\n",
    "                        self.total_list[self.index_list[i]].append(clean_str)\n",
    "            print('数据爬取成功！')\n",
    "        except:\n",
    "            print('子HTML解析失败（可能页面被更新过）')\n",
    "\n",
    "    def main(self):\n",
    "        '''\n",
    "        入口函数\n",
    "        :return:\n",
    "        '''\n",
    "        detail_url_queue = Queue(maxsize=1000)\n",
    "        thread = threading.Thread(target=self.parse_index_html, args=(detail_url_queue,))  # 该线程负责填充子url队列\n",
    "        html_thread = []\n",
    "        for i in range(4):\n",
    "            thread2 = threading.Thread(target=self.son_request, args=(detail_url_queue,))  # 该线程负责爬取子url数据\n",
    "            html_thread.append(thread2)\n",
    "        # 启动四个线程\n",
    "        thread.start()\n",
    "        for i in range(4):\n",
    "            html_thread[i].start()\n",
    "        thread.join()\n",
    "        for i in range(4):\n",
    "            html_thread[i].join()\n",
    "\n",
    "        # 写入EXCEL\n",
    "        self.data_to_excel()\n",
    "\n",
    "    def data_to_excel(self):\n",
    "        # 数据格式转置\n",
    "        my_df = pd.DataFrame.from_dict(self.total_list, orient='index').T\n",
    "        my_df.to_excel(self.save_filename, index=False)\n",
    "        print('写入成功')\n",
    "\n",
    "def change_c(word):\n",
    "    '''\n",
    "    将用户输入的中文转为拼音字母\n",
    "    :param word:\n",
    "    :return:\n",
    "    '''\n",
    "    s = ''\n",
    "    for i in pypinyin.pinyin(word, style=pypinyin.NORMAL):\n",
    "        s += ''.join(i)\n",
    "    return s\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    default_city = '徐州'\n",
    "    default_filename = 'PM25_data_xuzhou.xlsx'\n",
    "\n",
    "    str_value = input(f'请输入城市名（默认值：{default_city}）：') or default_city\n",
    "    filename = input(f'请输入保存文件名（包括文件后缀，如{default_filename}，默认值：{default_filename}）：') or default_filename\n",
    "\n",
    "    print('城市名：', change_c(str_value))\n",
    "    PM_DATA(str_value, filename).main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768801e-7995-49c5-8b08-9ed341fbed7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e4c4a-6ac8-4eb5-a714-16c524c21a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f040c2-e58e-436d-ac0d-122bd27164a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
